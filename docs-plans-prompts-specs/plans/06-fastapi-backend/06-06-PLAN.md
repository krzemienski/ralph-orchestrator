---
phase: 06-fastapi-backend
plan: 06
type: execute
domain: python-api
---

<objective>
Implement S3-compatible cloud storage for audio file uploads, downloads, and presigned URL generation.
</objective>

<context>
@BRIEF.md
@codestory/backend/core/config.py
</context>

<error_recovery>
S3/Cloud Storage is an external dependency. Implement robust handling:

**Upload Failures:**
1. Verify bucket exists and is accessible on startup
2. On upload failure, retry with exponential backoff (3 attempts)
3. Use multipart upload for files >100MB (with resume capability)
4. Validate file integrity with MD5/ETag after upload

**Download Failures:**
- Generate presigned URLs with appropriate expiry (1 hour default)
- If presigned URL fails, regenerate and retry once
- Return clear error if file doesn't exist (404 handling)

**Network/Timeout Issues:**
- Configure reasonable timeouts (connect: 5s, read: 30s)
- Use connection pooling for efficiency
- Retry on timeout/connection errors

**Permission Errors:**
- Fail fast on IAM permission issues (don't retry auth errors)
- Log detailed error for debugging
- Return user-friendly message ("storage temporarily unavailable")

**Storage Full/Quota:**
- Monitor bucket size if applicable
- Implement cleanup policy for old/orphaned files
- Alert before quota exhaustion

**Recovery Actions:**
- Failed uploads: store locally, queue for retry
- Orphaned files: background cleanup job
- Missing files: check if regeneration is possible

**Local Development:**
- Support MinIO or LocalStack for local testing
- Environment variable to switch between local/cloud storage
</error_recovery>

<tasks>

<task type="auto">
  <n>Task 1: Create S3 storage client</n>
  <files>codestory/backend/storage/s3.py, codestory/backend/storage/__init__.py</files>
  <action>
Create S3 storage module:

```python
"""S3 storage client for Code Story."""

import logging
from pathlib import Path
from typing import BinaryIO
from datetime import datetime

import boto3
from botocore.config import Config
from botocore.exceptions import ClientError

from backend.core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class S3StorageError(Exception):
    """S3 storage error."""
    pass


class S3Storage:
    """S3-compatible storage client for audio files."""
    
    def __init__(
        self,
        bucket: str | None = None,
        region: str | None = None,
        endpoint_url: str | None = None,
    ):
        self.bucket = bucket or settings.s3_bucket
        self.region = region or settings.aws_region
        self.endpoint_url = endpoint_url or settings.s3_endpoint_url
        
        self._client = boto3.client(
            "s3",
            region_name=self.region,
            endpoint_url=self.endpoint_url,
            aws_access_key_id=settings.aws_access_key_id,
            aws_secret_access_key=settings.aws_secret_access_key,
            config=Config(
                signature_version="s3v4",
                retries={"max_attempts": 3},
            ),
        )
    
    def upload_file(
        self,
        file_path: str | Path,
        key: str,
        content_type: str = "audio/mpeg",
        metadata: dict | None = None,
    ) -> str:
        """
        Upload a file to S3.
        
        Args:
            file_path: Local file path
            key: S3 object key
            content_type: MIME type
            metadata: Optional metadata dict
        
        Returns:
            S3 URL of uploaded file
        """
        try:
            extra_args = {
                "ContentType": content_type,
                "Metadata": metadata or {},
            }
            
            self._client.upload_file(
                str(file_path),
                self.bucket,
                key,
                ExtraArgs=extra_args,
            )
            
            logger.info(f"Uploaded {file_path} to s3://{self.bucket}/{key}")
            return self._get_url(key)
            
        except ClientError as e:
            logger.exception(f"Failed to upload {file_path}")
            raise S3StorageError(f"Upload failed: {e}")
    
    def upload_fileobj(
        self,
        file_obj: BinaryIO,
        key: str,
        content_type: str = "audio/mpeg",
        metadata: dict | None = None,
    ) -> str:
        """
        Upload a file object to S3.
        
        Args:
            file_obj: File-like object
            key: S3 object key
            content_type: MIME type
            metadata: Optional metadata dict
        
        Returns:
            S3 URL of uploaded file
        """
        try:
            extra_args = {
                "ContentType": content_type,
                "Metadata": metadata or {},
            }
            
            self._client.upload_fileobj(
                file_obj,
                self.bucket,
                key,
                ExtraArgs=extra_args,
            )
            
            logger.info(f"Uploaded file object to s3://{self.bucket}/{key}")
            return self._get_url(key)
            
        except ClientError as e:
            logger.exception(f"Failed to upload file object to {key}")
            raise S3StorageError(f"Upload failed: {e}")
    
    def download_file(
        self,
        key: str,
        file_path: str | Path,
    ) -> Path:
        """
        Download a file from S3.
        
        Args:
            key: S3 object key
            file_path: Local destination path
        
        Returns:
            Path to downloaded file
        """
        try:
            output_path = Path(file_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            self._client.download_file(
                self.bucket,
                key,
                str(output_path),
            )
            
            logger.info(f"Downloaded s3://{self.bucket}/{key} to {output_path}")
            return output_path
            
        except ClientError as e:
            logger.exception(f"Failed to download {key}")
            raise S3StorageError(f"Download failed: {e}")
    
    def get_presigned_url(
        self,
        key: str,
        expiration: int = 3600,
        response_content_type: str | None = None,
    ) -> str:
        """
        Generate a presigned URL for downloading.
        
        Args:
            key: S3 object key
            expiration: URL expiration in seconds
            response_content_type: Override content-type in response
        
        Returns:
            Presigned URL
        """
        try:
            params = {
                "Bucket": self.bucket,
                "Key": key,
            }
            
            if response_content_type:
                params["ResponseContentType"] = response_content_type
            
            url = self._client.generate_presigned_url(
                "get_object",
                Params=params,
                ExpiresIn=expiration,
            )
            
            return url
            
        except ClientError as e:
            logger.exception(f"Failed to generate presigned URL for {key}")
            raise S3StorageError(f"Presigned URL failed: {e}")
    
    def get_presigned_upload_url(
        self,
        key: str,
        expiration: int = 3600,
        content_type: str = "audio/mpeg",
    ) -> dict:
        """
        Generate a presigned URL for uploading.
        
        Args:
            key: S3 object key
            expiration: URL expiration in seconds
            content_type: Expected content type
        
        Returns:
            Dict with url and fields for upload
        """
        try:
            response = self._client.generate_presigned_post(
                self.bucket,
                key,
                Fields={"Content-Type": content_type},
                Conditions=[
                    {"Content-Type": content_type},
                    ["content-length-range", 1, 500 * 1024 * 1024],  # 500MB max
                ],
                ExpiresIn=expiration,
            )
            
            return response
            
        except ClientError as e:
            logger.exception(f"Failed to generate upload URL for {key}")
            raise S3StorageError(f"Upload URL failed: {e}")
    
    def delete_file(self, key: str) -> None:
        """Delete a file from S3."""
        try:
            self._client.delete_object(Bucket=self.bucket, Key=key)
            logger.info(f"Deleted s3://{self.bucket}/{key}")
        except ClientError as e:
            logger.exception(f"Failed to delete {key}")
            raise S3StorageError(f"Delete failed: {e}")
    
    def file_exists(self, key: str) -> bool:
        """Check if a file exists in S3."""
        try:
            self._client.head_object(Bucket=self.bucket, Key=key)
            return True
        except ClientError:
            return False
    
    def _get_url(self, key: str) -> str:
        """Get public URL for object."""
        if self.endpoint_url:
            return f"{self.endpoint_url}/{self.bucket}/{key}"
        return f"https://{self.bucket}.s3.{self.region}.amazonaws.com/{key}"


# Default storage instance
storage = S3Storage()


def get_story_audio_key(story_id: str, filename: str = "story.mp3") -> str:
    """Generate S3 key for story audio."""
    return f"stories/{story_id}/audio/{filename}"


def get_story_chapter_key(story_id: str, chapter_num: int) -> str:
    """Generate S3 key for chapter audio."""
    return f"stories/{story_id}/chapters/chapter_{chapter_num:02d}.mp3"


def get_story_metadata_key(story_id: str) -> str:
    """Generate S3 key for story metadata."""
    return f"stories/{story_id}/metadata.json"
```

Create __init__.py:

```python
"""Storage package for Code Story."""

from backend.storage.s3 import (
    S3Storage,
    S3StorageError,
    storage,
    get_story_audio_key,
    get_story_chapter_key,
    get_story_metadata_key,
)

__all__ = [
    "S3Storage",
    "S3StorageError",
    "storage",
    "get_story_audio_key",
    "get_story_chapter_key",
    "get_story_metadata_key",
]
```
  </action>
  <verify>python -c "from codestory.backend.storage.s3 import S3Storage; print('S3 OK')"</verify>
  <done>S3 storage client created</done>
</task>

<task type="auto">
  <n>Task 2: Create storage router</n>
  <files>codestory/backend/api/routers/storage.py</files>
  <action>
Create storage endpoints:

```python
"""Storage router for Code Story API."""

from fastapi import APIRouter
from fastapi.responses import RedirectResponse

from backend.api.deps import CurrentUser, DBSession
from backend.api.exceptions import NotFoundError, ForbiddenError
from backend.storage.s3 import (
    storage,
    get_story_audio_key,
    get_story_chapter_key,
)
from backend.models.story import Story

router = APIRouter()


@router.get("/stories/{story_id}/audio")
async def get_story_audio_url(
    story_id: str,
    user: CurrentUser,
    db: DBSession,
) -> dict:
    """
    Get presigned URL for story audio download.
    
    Returns a temporary URL valid for 1 hour.
    """
    story = await _get_user_story(db, story_id, user.id)
    
    key = get_story_audio_key(story_id)
    
    if not storage.file_exists(key):
        raise NotFoundError("Audio file", story_id)
    
    url = storage.get_presigned_url(
        key,
        expiration=3600,
        response_content_type="audio/mpeg",
    )
    
    return {
        "url": url,
        "expires_in": 3600,
        "content_type": "audio/mpeg",
    }


@router.get("/stories/{story_id}/audio/stream")
async def stream_story_audio(
    story_id: str,
    user: CurrentUser,
    db: DBSession,
) -> RedirectResponse:
    """
    Redirect to presigned URL for audio streaming.
    
    Useful for audio players that need direct URL access.
    """
    story = await _get_user_story(db, story_id, user.id)
    
    key = get_story_audio_key(story_id)
    
    if not storage.file_exists(key):
        raise NotFoundError("Audio file", story_id)
    
    url = storage.get_presigned_url(key, expiration=3600)
    
    return RedirectResponse(url=url, status_code=302)


@router.get("/stories/{story_id}/chapters/{chapter_num}/audio")
async def get_chapter_audio_url(
    story_id: str,
    chapter_num: int,
    user: CurrentUser,
    db: DBSession,
) -> dict:
    """Get presigned URL for chapter audio."""
    story = await _get_user_story(db, story_id, user.id)
    
    key = get_story_chapter_key(story_id, chapter_num)
    
    if not storage.file_exists(key):
        raise NotFoundError("Chapter audio", f"{story_id}/chapter_{chapter_num}")
    
    url = storage.get_presigned_url(key, expiration=3600)
    
    return {
        "url": url,
        "expires_in": 3600,
        "chapter_number": chapter_num,
    }


async def _get_user_story(db, story_id: str, user_id) -> Story:
    """Get story and verify ownership."""
    from uuid import UUID
    
    try:
        story_uuid = UUID(story_id)
    except ValueError:
        raise NotFoundError("Story", story_id)
    
    story = await db.get(Story, story_uuid)
    
    if not story:
        raise NotFoundError("Story", story_id)
    
    if story.user_id != user_id:
        raise ForbiddenError("You don't have access to this story")
    
    return story
```
  </action>
  <verify>python -c "from codestory.backend.api.routers.storage import router; print('Storage router OK')"</verify>
  <done>Storage router created</done>
</task>

</tasks>

<playwright_validation_gate>
```
# Get audio URL
Playwright Action: HTTP GET /api/storage/stories/{story_id}/audio
Headers: Authorization: Bearer {token}
Expected: 200 OK with presigned URL

# Stream redirect
Playwright Action: HTTP GET /api/storage/stories/{story_id}/audio/stream
Expected: 302 Redirect to S3 presigned URL

# Download audio
Playwright Action: HTTP GET {presigned_url}
Expected: 200 OK with audio/mpeg content
```
</playwright_validation_gate>
