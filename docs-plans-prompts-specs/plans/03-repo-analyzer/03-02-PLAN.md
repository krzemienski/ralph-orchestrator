---
phase: 03-repo-analyzer
plan: 02
type: execute
domain: python-api
---

<objective>
Implement analysis extraction skill that processes RepoMix output to identify architecture, patterns, and key components.

Purpose: Transform raw RepoMix data into structured analysis suitable for story generation.
Output: Analysis extraction skill with architecture detection, dependency mapping, and component identification.
</objective>


<context>
@BRIEF.md
@ROADMAP.md
@codestory/backend/skills/repomix/client.py
@codestory/backend/skills/repomix/skills.py
</context>

<opus_4_5_considerations>
Analysis extraction should:
- Process RepoMix output to identify meaningful patterns
- Detect common architectural patterns (MVC, microservices, monolith)
- Map dependencies between modules and files
- Identify entry points, configuration, and core business logic

Opus 4.5 prompt considerations:
- Provide rich context from RepoMix output
- Ask for structured JSON responses with reasoning
- Use effort="high" for complex pattern recognition

Avoid: Hardcoding language-specific patterns only, missing dependency relationships, no architecture inference.
</opus_4_5_considerations>

<tasks>

<task type="auto">
  <n>Task 1: Create analysis extraction skill</n>
  <files>codestory/backend/skills/analysis/extractor.py, codestory/backend/skills/analysis/__init__.py</files>
  <action>
Create analysis extraction skill that uses Claude to analyze RepoMix output:

```python
# extractor.py
"""Analysis extraction skill for repository understanding."""

from dataclasses import dataclass, field
from typing import Any
import json

from backend.agents.base import BaseAgent, AgentConfig
from backend.core.config import get_settings
from backend.skills.decorators import skill
from backend.skills.repomix import RepoMixOutput, RepoMixFile


@dataclass
class RepositoryAnalysis:
    """Structured analysis of a repository."""
    # Basic info
    name: str
    description: str | None
    primary_language: str
    
    # Architecture
    architecture_pattern: str  # monolith, microservices, library, cli, etc.
    architecture_description: str
    
    # Components
    entry_points: list[str]
    core_modules: list[dict[str, Any]]
    configuration_files: list[str]
    
    # Dependencies
    external_dependencies: list[str]
    internal_dependencies: dict[str, list[str]]  # module -> depends_on
    
    # Key files for story
    key_files: list[dict[str, str]]  # path, purpose, importance
    
    # Patterns detected
    design_patterns: list[str]
    frameworks: list[str]
    
    # Metrics
    total_files: int
    total_lines: int
    complexity_score: str  # low, medium, high


ANALYSIS_SYSTEM_PROMPT = '''You are an expert software architect analyzing a repository.
Given the repository structure and file contents, extract a comprehensive analysis.

Your analysis should identify:
1. **Architecture Pattern**: Is this a monolith, microservices, library, CLI tool, web app, etc.?
2. **Core Components**: What are the main modules and their responsibilities?
3. **Entry Points**: Where does execution start? (main files, API routes, CLI commands)
4. **Dependencies**: What external packages are used? How do internal modules depend on each other?
5. **Key Files**: Which files are most important for understanding the codebase?
6. **Design Patterns**: What patterns are evident? (MVC, Factory, Observer, etc.)

Respond with a JSON object matching the specified schema.
Be specific and cite file paths when identifying components.'''


ANALYSIS_USER_TEMPLATE = '''Analyze this repository:

## Repository Info
- URL: {repo_url}
- Total Files: {total_files}
- Total Characters: {total_characters}

## File Tree
{file_tree}

## Key Files Content

{key_files_content}

---

Provide your analysis as JSON with this structure:
{{
  "name": "repository name",
  "description": "brief description",
  "primary_language": "python/javascript/etc",
  "architecture_pattern": "monolith/microservices/library/cli/webapp",
  "architecture_description": "explanation of the architecture",
  "entry_points": ["path/to/main.py", "path/to/cli.py"],
  "core_modules": [
    {{"name": "module_name", "path": "path/to/module", "purpose": "what it does"}}
  ],
  "configuration_files": ["pyproject.toml", "config.yaml"],
  "external_dependencies": ["fastapi", "pydantic", "sqlalchemy"],
  "internal_dependencies": {{
    "api": ["db", "services"],
    "services": ["models"]
  }},
  "key_files": [
    {{"path": "src/main.py", "purpose": "Application entry point", "importance": "critical"}}
  ],
  "design_patterns": ["factory", "dependency injection", "repository"],
  "frameworks": ["FastAPI", "SQLAlchemy"],
  "total_files": {total_files},
  "total_lines": 0,
  "complexity_score": "low/medium/high"
}}'''


@skill(
    name="analyze_repository",
    description="Analyze repository structure and identify architecture, patterns, and key components",
)
async def analyze_repository(
    repomix_output: dict[str, Any],
) -> dict[str, Any]:
    """
    Analyze a repository from RepoMix output.
    
    Args:
        repomix_output: Output from pack_repository skill
    
    Returns:
        Structured analysis of repository architecture and components
    """
    settings = get_settings()
    
    # Extract key files content for analysis
    key_files_content = _extract_key_files_content(repomix_output)
    
    # Build analysis prompt
    file_tree = "\n".join(repomix_output.get("file_tree", [])[:200])
    
    user_prompt = ANALYSIS_USER_TEMPLATE.format(
        repo_url=repomix_output.get("repo_url", "unknown"),
        total_files=repomix_output.get("total_files", 0),
        total_characters=repomix_output.get("total_characters", 0),
        file_tree=file_tree,
        key_files_content=key_files_content,
    )
    
    # Create analysis agent
    from anthropic import Anthropic
    
    client = Anthropic()
    
    response = client.messages.create(
        model=settings.claude_model,
        max_tokens=4000,
        system=ANALYSIS_SYSTEM_PROMPT,
        messages=[{"role": "user", "content": user_prompt}],
    )
    
    # Parse response
    try:
        response_text = response.content[0].text
        # Extract JSON from response (handle markdown code blocks)
        if "```json" in response_text:
            json_str = response_text.split("```json")[1].split("```")[0]
        elif "```" in response_text:
            json_str = response_text.split("```")[1].split("```")[0]
        else:
            json_str = response_text
        
        analysis = json.loads(json_str.strip())
        return {"analysis": analysis, "status": "success"}
    except (json.JSONDecodeError, IndexError) as e:
        return {
            "error": f"Failed to parse analysis response: {e}",
            "raw_response": response_text if 'response_text' in dir() else None,
        }


def _extract_key_files_content(repomix_output: dict[str, Any]) -> str:
    """Extract content from key files for analysis."""
    key_file_patterns = [
        "README", "readme",
        "pyproject.toml", "package.json", "Cargo.toml", "go.mod",
        "main.py", "app.py", "index.ts", "index.js",
        "setup.py", "setup.cfg",
        "__init__.py",  # root init
        "config", "settings",
    ]
    
    files = repomix_output.get("files", [])
    key_content_parts = []
    total_chars = 0
    max_chars = 50000  # Limit total content for analysis
    
    for file_data in files:
        path = file_data.get("path", "")
        preview = file_data.get("preview", "")
        
        # Check if this is a key file
        is_key = any(pattern.lower() in path.lower() for pattern in key_file_patterns)
        
        if is_key and preview and total_chars < max_chars:
            content = preview[:2000]  # Limit per-file content
            key_content_parts.append(f"### {path}\n```\n{content}\n```\n")
            total_chars += len(content)
    
    return "\n".join(key_content_parts) or "No key files content available."


@skill(
    name="identify_story_components",
    description="Identify components of a repository that would make good story chapters",
)
async def identify_story_components(
    analysis: dict[str, Any],
    intent: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Identify components suitable for story chapters.
    
    Args:
        analysis: Repository analysis from analyze_repository
        intent: Optional user intent to focus the story
    
    Returns:
        List of components with story relevance scores
    """
    if "analysis" not in analysis:
        return {"error": "Invalid analysis input"}
    
    repo_analysis = analysis["analysis"]
    
    # Build component list with story relevance
    components = []
    
    # Entry points are always important
    for entry in repo_analysis.get("entry_points", []):
        components.append({
            "type": "entry_point",
            "path": entry,
            "story_relevance": "high",
            "suggested_chapter": "The Beginning - Where It All Starts",
        })
    
    # Core modules
    for module in repo_analysis.get("core_modules", []):
        components.append({
            "type": "module",
            "name": module.get("name"),
            "path": module.get("path"),
            "purpose": module.get("purpose"),
            "story_relevance": "high",
            "suggested_chapter": f"The {module.get('name', 'Core')} - Heart of the System",
        })
    
    # Design patterns make good story elements
    patterns = repo_analysis.get("design_patterns", [])
    if patterns:
        components.append({
            "type": "patterns",
            "patterns": patterns,
            "story_relevance": "medium",
            "suggested_chapter": "The Architecture - Patterns That Shape the Code",
        })
    
    # Dependencies tell the external story
    deps = repo_analysis.get("external_dependencies", [])
    if deps:
        components.append({
            "type": "dependencies",
            "dependencies": deps[:10],  # Top 10
            "story_relevance": "medium",
            "suggested_chapter": "The Allies - Libraries That Power the System",
        })
    
    return {
        "components": components,
        "architecture_overview": repo_analysis.get("architecture_description"),
        "complexity": repo_analysis.get("complexity_score"),
        "total_chapters_suggested": len(components),
    }
```

Create package init:

```python
# __init__.py
"""Repository analysis skills."""

from backend.skills.analysis.extractor import (
    RepositoryAnalysis,
    analyze_repository,
    identify_story_components,
)

__all__ = [
    "RepositoryAnalysis",
    "analyze_repository",
    "identify_story_components",
]
```

Avoid: Not using Claude for analysis, hardcoded pattern matching only, missing story component mapping.
  </action>
  <verify>python -c "from codestory.backend.skills.analysis.extractor import analyze_repository; print('Analysis skill OK')"</verify>
  <done>Analysis extraction skill imports successfully</done>
</task>

<task type="auto">
  <n>Task 2: Create Repository Analyzer Agent</n>
  <files>codestory/backend/agents/repo_analyzer.py</files>
  <action>
Create the Repository Analyzer Agent that orchestrates RepoMix and analysis:

```python
"""Repository Analyzer Agent for code understanding."""

from typing import Any

from backend.agents.base import BaseAgent, AgentConfig, AgentRole
from backend.core.config import get_settings
from backend.skills.repomix import pack_repository, get_repository_structure
from backend.skills.analysis import analyze_repository, identify_story_components


REPO_ANALYZER_SYSTEM_PROMPT = '''You are the Repository Analyzer Agent for Code Story.

Your role is to deeply understand codebases and extract meaningful insights for story generation.

## Your Capabilities
You have access to these skills:
1. **pack_repository** - Pack a GitHub repository using RepoMix
2. **get_repository_structure** - Get file tree and project type
3. **analyze_repository** - Perform deep analysis of architecture and patterns
4. **identify_story_components** - Find components suitable for story chapters

## Your Process
When analyzing a repository:
1. First, pack the repository to get its full content
2. Analyze the structure to understand the architecture
3. Identify key components and patterns
4. Map components to potential story chapters

## Output Format
Always provide structured analysis that the Story Architect can use:
- Architecture overview
- Key components with their roles
- Suggested story structure based on code organization
- Complexity assessment

Be thorough but efficient. Focus on elements that would make compelling narrative content.'''


class RepoAnalyzerAgent(BaseAgent):
    """Agent for analyzing repository structure and patterns."""
    
    def __init__(self):
        settings = get_settings()
        config = AgentConfig(
            role=AgentRole.ANALYZER,
            name="Repository Analyzer",
            model=settings.claude_model,
            system_prompt=REPO_ANALYZER_SYSTEM_PROMPT,
            max_iterations=5,
        )
        super().__init__(config)
        
        # Register skills
        self.register_skill(pack_repository)
        self.register_skill(get_repository_structure)
        self.register_skill(analyze_repository)
        self.register_skill(identify_story_components)
    
    async def analyze(
        self,
        repo_url: str,
        intent: dict[str, Any] | None = None,
        compress: bool = True,
    ) -> dict[str, Any]:
        """
        Perform full repository analysis.
        
        Args:
            repo_url: GitHub repository URL
            intent: Optional user intent from Intent Agent
            compress: Use RepoMix compression
        
        Returns:
            Complete repository analysis with story components
        """
        # Step 1: Pack repository
        packed = await pack_repository(
            repo_url=repo_url,
            compress=compress,
        )
        
        if "error" in packed:
            return {"error": f"Failed to pack repository: {packed['error']}"}
        
        # Step 2: Analyze structure
        analysis = await analyze_repository(repomix_output=packed)
        
        if "error" in analysis:
            return {"error": f"Analysis failed: {analysis['error']}"}
        
        # Step 3: Identify story components
        components = await identify_story_components(
            analysis=analysis,
            intent=intent,
        )
        
        return {
            "repo_url": repo_url,
            "packed_stats": {
                "total_files": packed.get("total_files"),
                "total_tokens": packed.get("total_tokens"),
                "compressed": packed.get("compressed"),
            },
            "analysis": analysis.get("analysis"),
            "story_components": components.get("components"),
            "suggested_chapters": components.get("total_chapters_suggested"),
            "status": "complete",
        }
    
    async def quick_structure(self, repo_url: str) -> dict[str, Any]:
        """Get quick repository structure without full analysis."""
        return await get_repository_structure(repo_url=repo_url)


# Singleton instance
repo_analyzer_agent = RepoAnalyzerAgent()
```

Avoid: Missing skill registration, no error propagation, not using intent for focused analysis.
  </action>
  <verify>python -c "from codestory.backend.agents.repo_analyzer import RepoAnalyzerAgent; print('Repo Analyzer Agent OK')"</verify>
  <done>Repository Analyzer Agent imports successfully</done>
</task>

<task type="auto">
  <n>Task 3: Create analysis API endpoints</n>
  <files>codestory/backend/api/routes/analyze.py</files>
  <action>
Create analysis API endpoints:

```python
"""Repository analysis API endpoints."""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel

from backend.agents.repo_analyzer import repo_analyzer_agent


router = APIRouter(prefix="/analyze", tags=["analysis"])


class AnalyzeRequest(BaseModel):
    """Request for repository analysis."""
    repo_url: str
    compress: bool = True
    intent: dict | None = None


class QuickStructureRequest(BaseModel):
    """Request for quick structure check."""
    repo_url: str


@router.post("/full")
async def analyze_full(request: AnalyzeRequest):
    """
    Perform full repository analysis.
    
    This includes:
    - Packing repository with RepoMix
    - Deep architecture analysis
    - Story component identification
    """
    result = await repo_analyzer_agent.analyze(
        repo_url=request.repo_url,
        intent=request.intent,
        compress=request.compress,
    )
    
    if "error" in result:
        raise HTTPException(status_code=400, detail=result)
    
    return result


@router.post("/structure")
async def analyze_structure(request: QuickStructureRequest):
    """
    Get quick repository structure.
    
    Returns file tree and detected project type without full analysis.
    """
    result = await repo_analyzer_agent.quick_structure(
        repo_url=request.repo_url,
    )
    
    if "error" in result:
        raise HTTPException(status_code=400, detail=result)
    
    return result


@router.get("/health")
async def analyze_health():
    """Check analysis service health."""
    import shutil
    
    npx_available = shutil.which("npx") is not None
    
    return {
        "status": "healthy" if npx_available else "degraded",
        "agent": "repo_analyzer",
        "npx_available": npx_available,
    }
```

Update main.py to include analyze router.

Avoid: Missing health check, no error handling, endpoints without validation.
  </action>
  <verify>python -c "from codestory.backend.api.routes.analyze import router; print('Analyze router OK')"</verify>
  <done>Analysis API router imports successfully</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] analyze_repository skill uses Claude for deep analysis
- [ ] identify_story_components maps analysis to chapters
- [ ] RepoAnalyzerAgent orchestrates full analysis pipeline
- [ ] API endpoints handle errors gracefully
</verification>

<success_criteria>
- Analysis extracts architecture patterns from RepoMix output
- Story components are identified with chapter suggestions
- Agent coordinates multi-step analysis process
- API provides both quick and full analysis options
</success_criteria>

<playwright_validation_gate>
**Playwright MCP Validation Required**

```
# Test quick structure
Playwright Action: HTTP POST /analyze/structure
Body: {"repo_url": "https://github.com/pallets/click"}
Expected: 200 OK
Assert: response.json().project_type.primary == "python"

# Test full analysis (longer timeout needed)
Playwright Action: HTTP POST /analyze/full
Body: {"repo_url": "https://github.com/pallets/click", "compress": true}
Expected: 200 OK
Assert: response.json().status == "complete"
Assert: response.json().analysis.architecture_pattern exists
Assert: response.json().story_components.length > 0
```
</playwright_validation_gate>

<o>
After completion, create `plans/03-repo-analyzer/03-02-SUMMARY.md`:

# Phase 3 Plan 2: Analysis Extraction Skill Summary

**Implemented analysis extraction and Repository Analyzer Agent.**

## Accomplishments
- Created analyze_repository skill using Claude for deep analysis
- Built identify_story_components for chapter mapping
- Implemented RepoAnalyzerAgent with skill orchestration
- Created /analyze API endpoints

## Files Created
- `codestory/backend/skills/analysis/extractor.py` - Analysis skills
- `codestory/backend/skills/analysis/__init__.py` - Package exports
- `codestory/backend/agents/repo_analyzer.py` - Analyzer agent
- `codestory/backend/api/routes/analyze.py` - API endpoints

## Decisions Made
- Using Claude for pattern recognition (not hardcoded rules)
- JSON schema for structured analysis output
- Story component mapping with chapter suggestions
- Quick structure vs full analysis separation

## Key Features
- Architecture pattern detection (monolith, microservices, etc.)
- Design pattern identification
- Dependency mapping (internal and external)
- Story-relevant component scoring

## Next Step
Ready for 03-03-PLAN.md (Repository Analyzer Agent assembly)
</o>
